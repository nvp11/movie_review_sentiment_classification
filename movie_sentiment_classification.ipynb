{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text file programmatically\n",
    "# filter the complete the sentences (you will get like 6000 approx number of complete sentences)\n",
    "# select 50 setences randomly out of 6000 sentences\n",
    "# print those 50 sentences here\n",
    "# do manually analysis to find indicative features/words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import islice\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nnll performance summary =  0.48383582711223ll performance summary =  0.483ll performance summary =  0.4838358271122383582711223\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "vectorizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    \n",
    "    df = pd.read_csv(file_path, sep = '\\t')\n",
    "    df.head()\n",
    "    return dfll performance summary =  0.48383582711223\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_and_sentiments(df):\n",
    "    counter = 0 \n",
    "    Id = 1\n",
    "    list_of_sentences = []\n",
    "    word_in_sent = []\n",
    "    list_of_sentiments = []\n",
    "    for num in range(len(df['SentenceId'])):\n",
    "\n",
    "        #if Id == df['SentenceId'][counter]:\n",
    "        list_of_sentences.append(df['Phrase'][num])\n",
    "        list_of_sentiments.append(df['Sentiment'][num])\n",
    "\n",
    "            #print(str(Id) + \") \" + df['Phrase'][counter] + str(df['Sentiment'][counter]) +\"\\n\")\n",
    "            #Id = Id + 1 \n",
    "        #counter = counter + 1 \n",
    "    #print(list_of_sentences)\n",
    "    #print(list_of_sentiments) \n",
    "\n",
    "    y = np.array(list_of_sentiments)\n",
    "    print(y)\n",
    "    return list_of_sentences, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(list_of_sentences,y):\n",
    "    train_list_of_sentence = []\n",
    "    test_list_of_sentence = []\n",
    "    split_index = int(len(list_of_sentences)*0.2)\n",
    "    #length_to_split = [int(len(list_of_sentences)*0.8), int(len(list_of_sentences)*0.2)]\n",
    "    #sen = iter(list_of_sentences)\n",
    "    #sentences = [list(islice(sen,elem))\n",
    "    #            for elem in length_to_split]\n",
    "    #print(sentences)\n",
    "    print(\"list of sentences \" , len(list_of_sentences))\n",
    "    print(\"Slpit_index\", split_index)\n",
    "    train_list_of_sentence = list_of_sentences[ :-split_index]\n",
    "\n",
    "    test_list_of_sentence = list_of_sentences[-split_index: ]\n",
    "\n",
    "    print(len(test_list_of_sentence))\n",
    "    \n",
    "    y_train=y[ :-split_index]\n",
    "    y_test = y[-split_index: ]\n",
    "    print(\"y_train\", len(y_train))\n",
    "    print(\"y_test\", len(y_test))\n",
    "    return train_list_of_sentence, test_list_of_sentence,y_test,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence_to_vector(sentences): #,test_list_of_sentence):\n",
    "    global vectorizer\n",
    "    \n",
    "    if vectorizer == None:\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(sentences)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    X_vec = vectorizer.transform(sentences)\n",
    "    \n",
    "    '''print(X_train.shape)\n",
    "    print(type(X_train))\n",
    "    X_train_dense = X_train.todense()ll performance summary =  0.48383582711223\n",
    "    print(X_train_dense.shape)\n",
    "\n",
    "    print(sys.getsizeof(X_train_dense))\n",
    "    print(X_train_dense[10].tolist())'''\n",
    "    return X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train,y_train):\n",
    "    reg = LogisticRegression().fit(X_train, y_train)\n",
    "    return reg\n",
    "def prediction(reg, X_test):\n",
    "    predections = reg.predict(X_test)\n",
    "    print(\"prediction\", predections.shape)\n",
    "    return predections\n",
    "\n",
    "def evulate(predections, y_test):\n",
    "    score = accuracy_score(y_test, predections)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 ... 3 2 2]\n",
      "156059\n",
      "list of sentences  156059\n",
      "Slpit_index 31211\n",
      "31211\n",
      "y_train 124848\n",
      "y_test 31211\n",
      "y_train 124848\n",
      "X_train 124848\n",
      "X_test 31211\n",
      "y_test 31211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nidhi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/nidhi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (31211,)\n",
      "0.5829355035083784\n"
     ]
    }
   ],
   "source": [
    "data = read_file(\"/home/nidhi/Projects_Jupyter_Notebook/Movie_sentiments_classifier/train.tsv\")\n",
    "all_sentences, all_sentiments = get_sentences_and_sentiments(data)\n",
    "print(len(all_sentences))\n",
    "X_train, X_test, y_test, y_train = split_data(all_sentences,all_sentiments)\n",
    "vector_train = convert_sentence_to_vector(X_train)\n",
    "print(\"y_train\", len(y_train))\n",
    "print(\"X_train\", len(X_train))\n",
    "print(\"X_test\", len(X_test))\n",
    "print(\"y_test\", len(y_test))\n",
    "vector_test = convert_sentence_to_vector(X_test)\n",
    "clf = train_classifier(vector_train, y_train)\n",
    "pre = prediction(clf,vector_test)\n",
    "evu = evulate(pre, y_test)\n",
    "print(evu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 100)\n",
      "(400001, 100)\n"
     ]
    }
   ],
   "source": [
    "word_to_index = pickle.load(open(\"/home/nidhi/Projects_Jupyter_Notebook/PycharmProjects/practice_glove/word_index.pkl\", \"rb\"))\n",
    "word_to_index['OoV'] = len(word_to_index)\n",
    "glove_embeddings = pickle.load(open(\"/home/nidhi/Projects_Jupyter_Notebook/PycharmProjects/practice_glove/glove_lookup_matrix.pkl\", \"rb\"))\n",
    "print(glove_embeddings.shape)\n",
    "\n",
    "numpy.random.seed(56)\n",
    "OoV_vector = numpy.random.rand(100)\n",
    "glove_embeddings = numpy.vstack([glove_embeddings, OoV_vector])\n",
    "print(glove_embeddings.shape)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sent_to_index(sentence):\n",
    "    var_index = []\n",
    "    words = word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        \n",
    "        if word_to_index.get(word) == None:\n",
    "            var_index.append(word_to_index['OoV'])\n",
    "        else:\n",
    "            var_index.append(word_to_index.get(word))\n",
    "    return var_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class movie_sentiments_one_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features=100, h1 = 100, out_features = 5):\n",
    "        \n",
    "        super(movie_sentiments_one_layer, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.out = nn.Linear(h1, out_features)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.from_numpy(glove_embeddings))\n",
    "    \n",
    "    def forward(self,x_sentences):\n",
    "        x_vectors = []\n",
    "        \n",
    "        for sentence in x_sentences:\n",
    "            x_indices = convert_sent_to_index(sentence)\n",
    "            x_matrix = self.embedding(torch.from_numpy(numpy.array(x_indices)).long())\n",
    "            x_vector = torch.sum(x_matrix, dim=0).reshape(1,100)\n",
    "            x_vectors.append(x_vector)\n",
    "        \n",
    "                \n",
    "        x_vectors = torch.cat(x_vectors, dim=0).float()\n",
    "        h1 = F.relu(self.fc1(x_vectors))\n",
    "        out = self.out(h1)\n",
    "        out = self.sigmoid(out)\n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = movie_sentiments_one_layer()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nidhi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 and loss is 1.6061348915100098\n",
      "epoch 1 and loss is 1.6013691425323486\n",
      "epoch 2 and loss is 1.5967177152633667\n",
      "epoch 3 and loss is 1.5923799276351929\n",
      "epoch 4 and loss is 1.5884723663330078\n",
      "epoch 5 and loss is 1.5849807262420654\n",
      "epoch 6 and loss is 1.581884503364563\n",
      "epoch 7 and loss is 1.5791338682174683\n",
      "epoch 8 and loss is 1.5766700506210327\n",
      "epoch 9 and loss is 1.5744224786758423\n"
     ]
    }
   ],
   "source": [
    "epochs = 10 \n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    # Forward and get a prediction \n",
    "    \n",
    "    y_pred = model.forward(X_train)\n",
    "    \n",
    "    # Calculate Loss/error\n",
    "    \n",
    "    loss = criterion(y_pred,torch.from_numpy(numpy.array(y_train)))\n",
    "    losses.append(loss)\n",
    "    \n",
    "    #if i % 10 ==0:\n",
    "    print(f'epoch {i} and loss is {loss}')\n",
    "        \n",
    "        \n",
    "    #Backpropogation\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(epochs),losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nidhi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        y_val = model.forward(X_test)\n",
    "        y_pred = numpy.argmax(y_val.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per class performance summary =  0.1380910316922874\n",
      "Over all performance summary =  0.483835827112236\n",
      "Classificaion Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1443\n",
      "           1       0.23      0.00      0.00      5918\n",
      "           2       0.49      0.97      0.65     15362\n",
      "           3       0.21      0.02      0.03      6605\n",
      "           4       0.00      0.00      0.00      1883\n",
      "\n",
      "    accuracy                           0.48     31211\n",
      "   macro avg       0.19      0.20      0.14     31211\n",
      "weighted avg       0.33      0.48      0.33     31211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(\"Per class performance summary = \" , f1_score(y_test, y_pred, average = 'macro'))\n",
    "print(\"Over all performance summary = \",f1_score(y_test, y_pred, average = 'micro'))\n",
    "\n",
    "print(\"Classificaion Report: \",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"words = []\\nf = open('/home/nidhi/words.txt').readlines()\\n\\nfor word in f:\\n    word.strip()\\n    words.append(word.strip())\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''words = []\n",
    "f = open('/home/nidhi/words.txt').readlines()\n",
    "\n",
    "for word in f:\n",
    "    word.strip()\n",
    "    words.append(word.strip())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'counter = 0 \\nId = 1\\nlist_of_sentences = []\\nword_in_sent = []\\nlist_of_sentiments = []\\nfor num in range(len(df[\\'SentenceId\\'])):\\n    \\n    if Id == df[\\'SentenceId\\'][counter]:\\n        list_of_sentences.append(df[\\'Phrase\\'][counter])\\n        list_of_sentiments.append(df[\\'Sentiment\\'][counter])\\n        \\n        #print(str(Id) + \") \" + df[\\'Phrase\\'][counter] + str(df[\\'Sentiment\\'][counter]) +\"\\n\")\\n        Id = Id + 1 \\n    counter = counter + 1 \\n#print(list_of_sentences)\\n#print(list_of_sentiments) \\n\\ny = np.array(list_of_sentiments)\\nprint(y)\\n\\n\\n\\n\\n#print(words)\\n\\n#l = len(list_of_sentences)\\n\\nfor i in words:\\n    vector = []\\n    for sent in list_of_sentences:\\n        if i in sent:\\n            j = 1\\n            vector.append(j)\\n            \\n        else:\\n            j = 0\\n            vector.append(j)\\n        \\n    word_in_sent.append(vector)  \\nX = np.array(word_in_sent).T\\nprint(X.shape)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''counter = 0 \n",
    "Id = 1\n",
    "list_of_sentences = []\n",
    "word_in_sent = []\n",
    "list_of_sentiments = []\n",
    "for num in range(len(df['SentenceId'])):\n",
    "    \n",
    "    if Id == df['SentenceId'][counter]:\n",
    "        list_of_sentences.append(df['Phrase'][counter])\n",
    "        list_of_sentiments.append(df['Sentiment'][counter])\n",
    "        \n",
    "        #print(str(Id) + \") \" + df['Phrase'][counter] + str(df['Sentiment'][counter]) +\"\\n\")\n",
    "        Id = Id + 1 \n",
    "    counter = counter + 1 \n",
    "#print(list_of_sentences)\n",
    "#print(list_of_sentiments) \n",
    "\n",
    "y = np.array(list_of_sentiments)\n",
    "print(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(words)\n",
    "\n",
    "#l = len(list_of_sentences)\n",
    "\n",
    "for i in words:\n",
    "    vector = []\n",
    "    for sent in list_of_sentences:\n",
    "        if i in sent:\n",
    "            j = 1\n",
    "            vector.append(j)\n",
    "            \n",
    "        else:\n",
    "            j = 0\n",
    "            vector.append(j)\n",
    "        \n",
    "    word_in_sent.append(vector)  \n",
    "X = np.array(word_in_sent).T\n",
    "print(X.shape)'''\n",
    "#print(X)\n",
    "        \n",
    "#print(word_in_sent)\n",
    "    \n",
    "#print (Id)\n",
    "#print(counter)\n",
    "#print(list_of_sentences)\n",
    "\n",
    "#for i in range(len(list_of_sentences)):\n",
    "    #print(str(i) + \"\\t\" +list_of_sentences[i] + \"\\n\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_list_of_sentence = []\\ntest_list_of_sentence = []\\nlength_to_split = [2097,530]\\nsen = iter(list_of_sentences)\\nsentences = [list(islice(sen,elem))\\n            for elem in length_to_split]\\n#print(sentences)\\ntrain_list_of_sentence = sentences[0]\\n\\ntest_list_of_sentence = sentences[1]\\n\\nprint(len(test_list_of_sentence))'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_list_of_sentence = []\n",
    "test_list_of_sentence = []\n",
    "length_to_split = [2097,530]\n",
    "sen = iter(list_of_sentences)\n",
    "sentences = [list(islice(sen,elem))\n",
    "            for elem in length_to_split]\n",
    "#print(sentences)\n",
    "train_list_of_sentence = sentences[0]\n",
    "\n",
    "test_list_of_sentence = sentences[1]\n",
    "\n",
    "print(len(test_list_of_sentence))'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(list_of_sentences), len(list_of_sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = np.array(word_in_sent)\n",
    "#n = train_data.shape\n",
    "#print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(word_in_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random \n",
    "\n",
    "#for i in range(1,101):\n",
    "#    print(str(i) +\"\\t\" + random.choice(list_of_sentences) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vectorizer = CountVectorizer()\\nvectorizer.fit(train_list_of_sentence)\\nX_train = vectorizer.transform(train_list_of_sentence)\\nprint(X_train.shape)\\nprint(type(X_train))\\nX_train_dense = X_train.todense()\\nprint(X_train_dense.shape)\\n\\nprint(sys.getsizeof(X_train_dense))\\nprint(X_train_dense[10].tolist())'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_list_of_sentence)\n",
    "X_train = vectorizer.transform(train_list_of_sentence)\n",
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "X_train_dense = X_train.todense()\n",
    "print(X_train_dense.shape)\n",
    "\n",
    "print(sys.getsizeof(X_train_dense))\n",
    "print(X_train_dense[10].tolist())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_test = vectorizer.transform(sentences[1])\\nprint(X_test.shape)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X_test = vectorizer.transform(sentences[1])\n",
    "print(X_test.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_train=y[ :-530]\\ny_test = y[-530: ]\\nprint(len(y_train))\\nprint(len(y_test))'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''y_train=y[ :-530]\n",
    "y_test = y[-530: ]\n",
    "print(len(y_train))\n",
    "print(len(y_test))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reg = LogisticRegression().fit(X_train, y_train)\\npredections = reg.predict(X_test)\\nprint(predections.shape)\\npredections[:10]\\naccuracy_score(y_test, predections)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''reg = LogisticRegression(). activation function.fit(X_train, y_train)\n",
    "predections = reg.predict(X_test)\n",
    "print(predections.shape)\n",
    "predections[:10]\n",
    "accuracy_score(y_test, predections)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
